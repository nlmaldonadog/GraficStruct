{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlmaldonadog/GraficStruct/blob/master/Practica_1_Datos_de_entrada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92ZKt16ylghk"
      },
      "source": [
        "# Práctica 1: Datos de entrada\n",
        "*Máster en Ciencia de Datos y Aprendizaje Automático - Universidad de La Rioja*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante el desarrollo de esta práctica, resuelve los ejercicios en este cuaderno justo después de ser propuestos.\n",
        "\n",
        "Se valorará positivamente la documentación en las respuestas y la explicación de las mismas.\n",
        "\n",
        "No olvides guardar tus versiones intermedias en GitHub (menú \"Archivo\" >> \"Guardar una copia en GitHub\") y la definitiva antes de la fecha límite de entrega."
      ],
      "metadata": {
        "id": "3kz2TSN2DQxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliografía:\n",
        "\n",
        "* https://elitedatascience.com/imbalanced-classes\n",
        "* Imbalanced: https://imbalanced-learn.org/stable/references/\n",
        "* SMOTE: https://arxiv.org/abs/1106.1813\n",
        "* Imblearn: https://imbalanced-learn.org/stable/references/generated/imblearn\n",
        "* ADASYN: [artículo ADASYN](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fsci2s.ugr.es%2Fkeel%2Fpdf%2Falgorithm%2Fcongreso%2F2008-He-ieee.pdf)"
      ],
      "metadata": {
        "id": "mKD4pWgrDoCs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHJZiM8Cmm7r"
      },
      "source": [
        "##Datos balanceados y no balanceados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTM3jF9Flo3N"
      },
      "source": [
        "#### Conjunto de datos ¿balanceado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSxSjTKOefJ1"
      },
      "source": [
        "Vamos a usar como entrada el conjunto de datos cuya descripción se encuentra en la siguiente URL \"https://www.kaggle.com/code/mysticvalley/balance-scale-analysis-and-prediction\".\n",
        "Son unos datos sintéticos y los vamos a usar para entender que ocurre cuando los datos se encuentran balanceados o no.\n",
        "\n",
        "Las variables L-Weight (var1), L-Distance (var2), R-Weight (var3) y R-Distance (var4) son numéricas y cada instancia ha sido clasificada de la siguiente manera\n",
        "*   si var1\\*var2=var3\\*var4 entonces se clasifica como B,\n",
        "*   si var1\\*var2 > var3\\*var4 entonces se clasifica como L\n",
        "*   si var1\\*var2 < var3\\*var4 entonces se clasifica como R\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEheIF9zekfO"
      },
      "source": [
        "Cargamos las librerías que vamos a utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkjkvQ7HeBsW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kx0XEkIetkJ"
      },
      "source": [
        "Para cargar los datos, accedemos al siguiente enlace de GitHub. También se podría hacer accediendo a la página de Kaggle, pero de esta manera evitamos el registro.\n",
        "\n",
        "Mostramos los 5 primeros valores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiMQFyMbO76H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "db99aae6-532f-40b1-ffb2-5ae8ea9e18ad"
      },
      "source": [
        "# Leer dataset\n",
        "url = \"https://raw.githubusercontent.com/gadeamm/DataSets_AAII/main/balance-scale.csv\"\n",
        "df = pd.read_csv(url, sep=\",\")\n",
        "\n",
        "# Mostrar las n primeras filas del dataset\n",
        "df.head(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Class  L-Weight  L-Distance  R-Weight  R-Distance\n",
              "0     B         1           1         1           1\n",
              "1     R         1           1         1           2\n",
              "2     R         1           1         1           3\n",
              "3     R         1           1         1           4\n",
              "4     R         1           1         1           5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-900efb62-cd9a-4149-87a5-7fbe17cfbc7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>L-Weight</th>\n",
              "      <th>L-Distance</th>\n",
              "      <th>R-Weight</th>\n",
              "      <th>R-Distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-900efb62-cd9a-4149-87a5-7fbe17cfbc7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-900efb62-cd9a-4149-87a5-7fbe17cfbc7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-900efb62-cd9a-4149-87a5-7fbe17cfbc7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e2b8921-8d51-4722-8b21-d4ab1aad97e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e2b8921-8d51-4722-8b21-d4ab1aad97e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e2b8921-8d51-4722-8b21-d4ab1aad97e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHOLCbSrYxbR"
      },
      "source": [
        "Vemos cuantas instancias hay de cada clase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ42IUViYxjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd1cc28-c6ff-4043-cb5b-19794e527d35"
      },
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "R    288\n",
              "L    288\n",
              "B     49\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmqLILjof8wP"
      },
      "source": [
        "Vemos que hay dos clases con el mismo número de datos (R y L) y otra que no (B).\n",
        "Para simplificar y hacer aún más exagerado el desbalanceo, vamos a convertir este problema, en un problema de clasificación binaria.\n",
        "\n",
        "Para ello vamos a re-etiquetar las instancias de la siguiente manera:\n",
        "- las observaciones que son R y L serán etiquetadas como 0 (clase negativa)\n",
        "- al resto de observaciones, las que están clasificadas como B, las re-etiquetaremos como 1 (clase positiva)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCdeZpbpZGem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456d53b8-31db-4d35-a420-8785273060a8"
      },
      "source": [
        "# Transformación del dataset a un conjunto binario\n",
        "df['Class'] = [1 if b=='B' else 0 for b in df.Class]\n",
        "\n",
        "# Mostrar el número de instancias para cada valor de la clase\n",
        "df['Class'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    576\n",
              "1     49\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGJfAXcMg-31"
      },
      "source": [
        "Como podemos ver, el 92% de la muestra es de la clase 0, esto quiere decir, que si **siempre** tuviéramos que predecir la clase 0, tendríamos un acierto del 92%.\n",
        "\n",
        "El problema surge que nosotros no vamos a querer clasificar siempre una misma clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHLobOFjh16H"
      },
      "source": [
        "Veamos como afecta un conjunto de datos balanceado o no a la solución de un problema.\n",
        "\n",
        "Para ello vamos a usar el algoritmo de Regresión Logística y el algoritmo k-NN (se explicarán con detenimiento más adelante) y la métrica de exactitud (o *accuracy*), todo de la librería Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU7SvGuEZc0w"
      },
      "source": [
        "#importamos las librerías correspondientes al algoritmo y la métrica\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3YLXaHhZnq9"
      },
      "source": [
        "A la hora de usar el algoritmo de Regresión Logística (que no nos engañe el nombre, es un algoritmo de clasificación), vamos a usarlo con los parámetros que vienen por defecto, ya que nuestra intención ahora es ver la diferencia entre datos balanceados y sin balancear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3RzhshYjZ_Z"
      },
      "source": [
        "Más adelante trabajaremos sobre como separar los datos para entrenar, testear y validar, en este punto vamos a entrenar y testear con todo el conjunto de datos, ya que no vamos a hacer ajuste de hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OopDjzEdZnVN"
      },
      "source": [
        "# Separamos las características (X) y la variable objetivo (y)\n",
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "\n",
        "# Entrenamos el modelo\n",
        "model_lr = LogisticRegression().fit(X, y)\n",
        "model_knn=KNeighborsClassifier().fit(X,y)\n",
        "\n",
        "# Predecimos sobre el conjunto de entreanmiento\n",
        "pred_y_lr = model_lr.predict(X)\n",
        "pred_y_knn=model_knn.predict(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IQhbeDRZyzj"
      },
      "source": [
        "Muchos algoritmos están diseñados para maximizar la exactitud (*accuracy*) por defecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MXI1yoWZ6Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e0067c-0c95-44c0-f0de-37dd2d5ef266"
      },
      "source": [
        "#¿Cómo es la accuracy?\n",
        "print( accuracy_score(pred_y_lr, y) )\n",
        "print( accuracy_score(pred_y_knn, y) )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9216\n",
            "0.9136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL0a9GrrZ_PM"
      },
      "source": [
        "Confirmamos así que el acierto de nuestro modelo es del 92% pero, ¿ocurre esto por qué sólo está prediciendo una clase?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2uVyxqwaADS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0b5e90-a499-4fe7-ed39-c73beb870878"
      },
      "source": [
        "# Mostramos los valores predichos (una vez cada valor)\n",
        "print( np.unique( pred_y_lr ) )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eosWh51XaHPh"
      },
      "source": [
        "De esta manera, comprobamos que este modelo sólo está prediciendo la clase 0, lo que significa que está ignorando la clase minoritaria a favor de la clase mayoritaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7iMQ1jqlh5j"
      },
      "source": [
        "EJERCICIO: comprueba si el modelo knn predice sólo una clase o por el contrario predice de las dos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( np.unique( pred_y_knn ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpwhzDK6RiK4",
        "outputId": "68a0ee6e-e9e7-4b5f-9bb0-374d40bc9058"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rta 0:\n",
        "Para este caso el modelo de knn si esta prediciendo ambas clases."
      ],
      "metadata": {
        "id": "9c3a_bmJUB1O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5RHN5pjltOz"
      },
      "source": [
        "Veamos dos técnicas para equilibrar esto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32KjwshOeZQX"
      },
      "source": [
        "##Remuestreo Aleatorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh0HNA1saK1J"
      },
      "source": [
        "####1. Aumentar la muestra de la clase minoritaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fW7yzIxaNI3"
      },
      "source": [
        "El proceso de aumentar la muestra consiste en duplicar aleatoriamente las observaciones de la clase minoritaria para reforzar su señal.\n",
        "\n",
        "Existen varias heurísticas para hacerlo, pero la forma más común es simplemente volver a muestrear con reemplazo.\n",
        "\n",
        "Veamos como podemos hacerlo, pero primero cargamos el modulo *resample* de Scikit-Learn que vamos a usar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUnQeUEAaBQE"
      },
      "source": [
        "from sklearn.utils import resample"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWzPuRypm2br"
      },
      "source": [
        "El primer paso es crear un nuevo *DataFrame* con el nuevo conjunto de datos para la clase minoritaria. Para ello:\n",
        "1. Separamos las instancias en grupos, un grupo por cada una de las clases que hay.\n",
        "2. Re-muestreamos la clase minoritaria usando remplazamineto, y obteniendo el mismo número de muestras que la clase mayoritaria.\n",
        "3. Finalmente, combinaremos en un nuevo *DataFrame* el nuevo grupo de datos de la clase que era minoritaria y el grupo original de la clase mayoritaria.\n",
        "Para nuestro ejemplo, el código sería el siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8mTKpEaUfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b781461e-fcfb-4a84-d656-8011f584fc64"
      },
      "source": [
        "# Separar las clases mayoritaria y minoritaria\n",
        "df_majority = df[df.Class==0]\n",
        "df_minority = df[df.Class==1]\n",
        "\n",
        "# Aumentar la muestra de la clase minoritaria\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,     # muestra con remplazamiento\n",
        "                                 n_samples=576,    # número de muestras de la clase mayoritaria\n",
        "                                 random_state=123) # semilla para que los resultados sean reproducibles\n",
        "\n",
        "# Combinar el nuevo grupo con el grupo original mayoritario\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Mostrar el número de instancias en cada clase\n",
        "df_upsampled.Class.value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    576\n",
              "1    576\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am_nSAZqab93"
      },
      "source": [
        "Como podemos ver, el nuevo *DataFrame* tiene más instancias que el original y ahora, el ratio entre las dos clases es de 1:1.\n",
        "\n",
        "Ahora, usando este conjunto de datos balanceado, vamos a entrenar un modelo de regresión logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBlzSU-_aajW"
      },
      "source": [
        "# Separar las características (X) y la variable objetivo o clase (y)\n",
        "y = df_upsampled.Class\n",
        "X = df_upsampled.drop('Class', axis=1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_lr = LogisticRegression().fit(X, y)\n",
        "\n",
        "# Predecir en el conjunto de entrenamiento\n",
        "pred_y_lr = model_lr.predict(X)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos cuáles y cuántas clases predice nuestro modelo\n",
        "print( np.unique( pred_y_lr ) )"
      ],
      "metadata": {
        "id": "_xTnUQeixQJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e776d5f7-c8cd-41f1-bec4-48acd432c227"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsvoE3GscVYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c6bbb6-4b0a-4d8d-a16b-d72ede66a180"
      },
      "source": [
        "# ¿qué accuracy tenemos ahora?\n",
        "print( accuracy_score(y, pred_y_lr) )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5147569444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxfl0YBQapX9"
      },
      "source": [
        "Observamos que ahora nuestro modelo no predice sólo una clase, sin embargo es cierto que la *accuracy* ha disminuido.Pero tenemos que tener en cuenta que este valor es significativo de lo que está sucediendo, de cuál es el rendimiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO: Entrena un modelo de k-NN (con los hiperparámetros por defecto), y comprueba si clasifica de las dos clases y obtén la *accuracy* de dicho modelo."
      ],
      "metadata": {
        "id": "LHbuqXPeyIQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_knn=KNeighborsClassifier().fit(X,y)\n",
        "pred_y_knn=model_knn.predict(X)\n",
        "print( np.unique( pred_y_knn ) )\n",
        "print( accuracy_score(y, pred_y_knn) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR0Az6sQSylY",
        "outputId": "8c4af412-1974-403e-dd53-45a7bab8847e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "0.9505208333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rta 1:\n",
        "Se puede observar que la accuracy es mucho mayor para el modelo de kNN, llegando hasta un 0,95, identificamos tambien que esta clasificando en las dos clases."
      ],
      "metadata": {
        "id": "KzC8_6CETycq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89g9YXBVat_c"
      },
      "source": [
        "####2. Disminuir la muestra de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MxwMShca38M"
      },
      "source": [
        "Disminuir el número de instancias de la clase mayoritaria implica la eliminación aleatoria de observaciones para evitar que su señal domine el algoritmo de aprendizaje.\n",
        "\n",
        "La heurística más común para hacerlo es el remuestreo sin reemplazo.\n",
        "\n",
        "El proceso es similar al de muestreo visto anteriormente:\n",
        "\n",
        "1. Separamos las instancias de cada clase en diferentes *DataFrame*.\n",
        "2. Volvemos a muestrear la clase mayoritaria, esta vez sin remplazo y estableciendo el número de muestras para que coincida con el de la clase minoritaria.\n",
        "3. Finalmente, combinaremos el nuevo *DataFrame* de la clase mayoritaria con el *DataFrame* original de la clase minoritaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXdGPRyKa7Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90a88df-effb-490b-95c2-fbf7d6e3dda9"
      },
      "source": [
        "# Separar las clases en diferentes DataFrame\n",
        "df_majority = df[df.Class==0]\n",
        "df_minority = df[df.Class==1]\n",
        "\n",
        "# Disminuir la clase mayoritaria\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                 replace=False,    # muestra sin remplazamiento\n",
        "                                 n_samples=49,     # número de muestras de la clase minoritaria\n",
        "                                 random_state=123) # semilla para que los datos sean reproducibles\n",
        "\n",
        "# Combinar el nuevo grupo con el grupo original minoritario\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Mostrar el número de instancias en cada clase\n",
        "df_downsampled.Class.value_counts()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    49\n",
              "1    49\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtwBJJ5NcKPQ"
      },
      "source": [
        "Esta vez, el nuevo *DataFrame* ha disminuido el número de instancias con respecto a su original, y el ratio entre las dos clases, vuelve a ser de 1:1.\n",
        "\n",
        "Veamos ahora que ocurre si entrenamos con el algoritmo de regresión logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN9ruFuLcN27"
      },
      "source": [
        "# Separar las características (X) y la variable objetivo o clase (y)\n",
        "y = df_downsampled.Class\n",
        "X = df_downsampled.drop('Class', axis=1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "clf_2 = LogisticRegression().fit(X, y)\n",
        "\n",
        "# Predecir en el conjunto de entrenamiento\n",
        "pred_y_2 = clf_2.predict(X)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos cuáles y cuántas clases predice nuestro modelo\n",
        "print( np.unique( pred_y_2 ) )"
      ],
      "metadata": {
        "id": "nXZUzTMYyDta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ca60d3-f4c8-4a24-b277-fb932f9eca45"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8uPpvqHcYb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5366025b-e278-4135-c2f1-107bd6b7c597"
      },
      "source": [
        "# ¿qué accuracy tenemos ahora?\n",
        "print( accuracy_score(y, pred_y_2) )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5612244897959183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNxcnYSKcmPk"
      },
      "source": [
        "Con esta técnica hemos vuelto a evitar que el modelo prediga sólo una clase y además parece que la *accuracy* es más alta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS5MTDVmeLnc"
      },
      "source": [
        "Veamos ahora otra técnica para balancear nuestras muestras."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO: Entrena un modelo de k-NN (con los hiperparámetros por defecto), y comprueba si clasifica de las dos clases y obtén la *accuracy* de dicho modelo."
      ],
      "metadata": {
        "id": "KBWN3N-Uy5GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_knn_2=KNeighborsClassifier().fit(X,y)\n",
        "pred_y_knn_2=model_knn_2.predict(X)\n",
        "print( np.unique( pred_y_knn_2 ) )\n",
        "print( accuracy_score(y, pred_y_knn_2) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqPqVLKtUz0G",
        "outputId": "de90d3b7-958b-4b37-9911-1a8c63f5f964"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "0.7959183673469388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rta 2:\n",
        "En este caso podemos observar el efectivamente si esta prediciendo ambas clases, pero, el accuracy se redujo mucho comparando con el ejercicio anterior. Sigue siendo mejor comparado contra el algoritmo de regresion logistica, pero el accuracy no mejora de la misma manera que al aumentar la clase minoritaria, por lo menos en este ejemplo"
      ],
      "metadata": {
        "id": "oGojNin_VPtj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBaaowWTsEh5"
      },
      "source": [
        "####3. Combinar ambas técnicas: aumentar y disminuir muestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDg-0uu_tOer"
      },
      "source": [
        "EJERCICIO: La clase mayoritaria tiene en nuestro ejemplo 576 instancias y la clase minoritaria 49, vamos a balancear el conjunto de datos aumentando la clase minoritaria y disminuyendo la clase mayoritaria a 312 muestras. Elegimos este número de instancias porque de esta manera hacemos que el número de muestras que se generan y que se eliminan en cada clase es el mismo.\n",
        "\n",
        "Comprueba que accuracy saldría para los modelos de Regresión Logística y k-NN.\n",
        "¿Qué modelo da mejor resultado?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar las clases mayoritaria y minoritaria\n",
        "df_majority_e3 = df[df.Class==0]\n",
        "df_minority_e3 = df[df.Class==1]\n",
        "\n",
        "# Aumentar la muestra de la clase minoritaria a 312\n",
        "df_minority_upsampled_e3 = resample(df_minority_e3,\n",
        "                                 replace=True,     # muestra con remplazamiento\n",
        "                                 n_samples=312,    # número de muestras de la clase mayoritaria\n",
        "                                 random_state=123) # semilla para que los resultados sean reproducibles\n",
        "\n",
        "# Disminuir la clase mayoritaria a 312\n",
        "df_majority_downsampled_e3 = resample(df_majority_e3,\n",
        "                                 replace=False,    # muestra sin remplazamiento\n",
        "                                 n_samples=312,     # número de muestras de la clase minoritaria\n",
        "                                 random_state=123) # semilla para que los datos sean reproducibles\n",
        "\n",
        "df_resampled_comb_e3 = pd.concat([df_majority_downsampled_e3, df_minority_upsampled_e3])\n",
        "df_resampled_comb_e3.Class.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9xCtd46WLjL",
        "outputId": "a96f5815-b2d8-433f-ac10-9b9beba46338"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    312\n",
              "1    312\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar las características (X) y la variable objetivo o clase (y)\n",
        "y_3 = df_resampled_comb_e3.Class\n",
        "X_3 = df_resampled_comb_e3.drop('Class', axis=1)\n",
        "\n",
        "# Entrenar el modelo LR y kNN\n",
        "model_lr_e3 = LogisticRegression().fit(X_3, y_3)\n",
        "pred_y_lr_e3 = model_lr_e3.predict(X_3)\n",
        "model_knn_e3 = KNeighborsClassifier().fit(X_3,y_3)\n",
        "pred_y_knn_3 = model_knn_e3.predict(X_3)\n",
        "\n",
        "print( \"Clases que esta prediciendo el algoritmo de regresion logistica\", np.unique( pred_y_lr_e3 ) )\n",
        "print( \"Accuracy del algoritmo de regresion logistica\", accuracy_score(y_3, pred_y_lr_e3) )\n",
        "print( \"Clases que esta prediciendo el algoritmo de kNN\", np.unique( pred_y_knn_3 ) )\n",
        "print( \"Accuracy del algoritmo de kNN\", accuracy_score(y_3, pred_y_knn_3) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jahyjThkXaN3",
        "outputId": "b3a6de80-615b-45fc-bcfc-a94103641dd8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases que esta prediciendo el algoritmo de regresion logistica [0 1]\n",
            "Accuracy del algoritmo de regresion logistica 0.530448717948718\n",
            "Clases que esta prediciendo el algoritmo de kNN [0 1]\n",
            "Accuracy del algoritmo de kNN 0.907051282051282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rta 3:\n",
        "Al combinar las tenicas podemos ver que para este problema en particular el algoritmo de kNN sigue siendo bastantemente mejor, en este caso tenemos una mejora sobre el caso de disminuir la muestra, pero el accuracy entregado por el algoritmo kNN a la hora de aumentar por completo la clase minoritaria sigue siendo mejor"
      ],
      "metadata": {
        "id": "K9xTx69OYiFo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTwH_Oqqu2zB"
      },
      "source": [
        "EJERCICO: Visto que ocurre aplicando cada técnica por separado y combinándolas ¿qué número de muestra crees que será una mejor elección para nuestro ejemplo?\n",
        "- aquella que requiera que el número de muestras de oversampling sea mayor (por ejemplo si el conjunto lo tomáramos de 400 instancias para cada clase)\n",
        "- o aquella que requiera que el número de muestras de oversampling sea menor (por ejemplo, con 100 instancias para cada clase).\n",
        "\n",
        "Probar si nuestra hipótesis es cierta para este ejemplo. ¿Qué ocurre?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar las clases mayoritaria y minoritaria\n",
        "df_majority_4 = df[df.Class==0]\n",
        "df_minority_4 = df[df.Class==1]\n",
        "\n",
        "\n",
        "df_minority_upsampled_4a = resample(df_minority_4,\n",
        "                                 replace=True,     # muestra con remplazamiento\n",
        "                                 n_samples=400,    # número de muestras de la clase mayoritaria\n",
        "                                 random_state=123) # semilla para que los resultados sean reproducibles\n",
        "df_majority_downsampled_4a = resample(df_majority_4,\n",
        "                                 replace=False,    # muestra sin remplazamiento\n",
        "                                 n_samples=400,    # número de muestras de la clase minoritaria\n",
        "                                 random_state=123) # semilla para que los datos sean reproducibles\n",
        "\n",
        "df_minority_upsampled_4b = resample(df_minority_4,\n",
        "                                 replace=True,     # muestra con remplazamiento\n",
        "                                 n_samples=100,    # número de muestras de la clase mayoritaria\n",
        "                                 random_state=123) # semilla para que los resultados sean reproducibles\n",
        "df_majority_downsampled_4b = resample(df_majority_4,\n",
        "                                 replace=False,    # muestra sin remplazamiento\n",
        "                                 n_samples=100,    # número de muestras de la clase minoritaria\n",
        "                                 random_state=123) # semilla para que los datos sean reproducibles\n",
        "\n",
        "df_resampled_comb_4a = pd.concat([df_majority_downsampled_4a, df_minority_upsampled_4a])\n",
        "df_resampled_comb_4b = pd.concat([df_majority_downsampled_4b, df_minority_upsampled_4b])\n",
        "print(\"Conteo primera parte del ejercicio\")\n",
        "print(df_resampled_comb_4a.Class.value_counts())\n",
        "y_4a = df_resampled_comb_4a.Class\n",
        "X_4a = df_resampled_comb_4a.drop('Class', axis=1)\n",
        "# Entrenar el modelo LR y kNN\n",
        "model_lr_4a = LogisticRegression().fit(X_4a, y_4a)\n",
        "pred_y_lr_4a = model_lr_4a.predict(X_4a)\n",
        "model_knn_4a = KNeighborsClassifier().fit(X_4a,y_4a)\n",
        "pred_y_knn_4a = model_knn_4a.predict(X_4a)\n",
        "\n",
        "print( \"Clases que esta prediciendo el algoritmo de regresion logistica para 400 muestras\", np.unique( pred_y_lr_4a ) )\n",
        "print( \"Accuracy del algoritmo de regresion logistica para 400 muestras\", accuracy_score(y_4a, pred_y_lr_4a) )\n",
        "print( \"Clases que esta prediciendo el algoritmo de kNN para 400 muestras\", np.unique( pred_y_knn_4a ) )\n",
        "print( \"Accuracy del algoritmo de kNN para 400 muestras\", accuracy_score(y_4a, pred_y_knn_4a) )\n",
        "\n",
        "print(\"Conteo segunda parte del ejercicio\")\n",
        "print(df_resampled_comb_4b.Class.value_counts())\n",
        "y_4b = df_resampled_comb_4b.Class\n",
        "X_4b = df_resampled_comb_4b.drop('Class', axis=1)\n",
        "# Entrenar el modelo LR y kNN\n",
        "model_lr_4b = LogisticRegression().fit(X_4b, y_4b)\n",
        "pred_y_lr_4b = model_lr_4b.predict(X_4b)\n",
        "model_knn_4b = KNeighborsClassifier().fit(X_4b,y_4b)\n",
        "pred_y_knn_4b = model_knn_4b.predict(X_4b)\n",
        "\n",
        "print( \"Clases que esta prediciendo el algoritmo de regresion logistica para 100 muestras\", np.unique( pred_y_lr_4b ) )\n",
        "print( \"Accuracy del algoritmo de regresion logistica para 100 muestras\", accuracy_score(y_4b, pred_y_lr_4b) )\n",
        "print( \"Clases que esta prediciendo el algoritmo de kNN para 100 muestras\", np.unique( pred_y_knn_4b ) )\n",
        "print( \"Accuracy del algoritmo de kNN para 100 muestras\", accuracy_score(y_4b, pred_y_knn_4b) )"
      ],
      "metadata": {
        "id": "HSGNPUpWaa54",
        "outputId": "1a7a2839-b572-474d-9ecc-726597349a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteo primera parte del ejercicio\n",
            "0    400\n",
            "1    400\n",
            "Name: Class, dtype: int64\n",
            "Clases que esta prediciendo el algoritmo de regresion logistica para 400 muestras [0 1]\n",
            "Accuracy del algoritmo de regresion logistica para 400 muestras 0.49625\n",
            "Clases que esta prediciendo el algoritmo de kNN para 400 muestras [0 1]\n",
            "Accuracy del algoritmo de kNN para 400 muestras 0.9275\n",
            "Conteo segunda parte del ejercicio\n",
            "0    100\n",
            "1    100\n",
            "Name: Class, dtype: int64\n",
            "Clases que esta prediciendo el algoritmo de regresion logistica para 100 muestras [0 1]\n",
            "Accuracy del algoritmo de regresion logistica para 100 muestras 0.55\n",
            "Clases que esta prediciendo el algoritmo de kNN para 100 muestras [0 1]\n",
            "Accuracy del algoritmo de kNN para 100 muestras 0.765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rta 4:\n",
        "Posterior a realizar estas ejecuciones podemos identificar que para el caso de esta muestra, el algoritmo de regresion logistica empeora entre mas datos se agregan a las muestras, por caso contrario, el algoritmo de kNN mejora conforme mas muestras de la clase minoritaria se incrementa con la finalidad de igualar a la clase mayoritaria"
      ],
      "metadata": {
        "id": "30C6N5VWdC-1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USWb_513v58_"
      },
      "source": [
        "EJERCICIO EXTRA: existe otra librería que incluye estos métodos de balanceo de datos [*imblearn*](https://imbalanced-learn.org/stable/references/) y los métodos se definen como *RandomOverSampler* y *RandomUnderSampler*. Lee como se usa y prueba a usarlos como hemos hecho con los métodos de la librería Scikit-Learn (oversampling, undersampling, y combinado). Obtén la *accuracy* para al menos uno de los modelos (LR y/o k-NN).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT7a8R3nefo9"
      },
      "source": [
        "### SMOTE: Synthetic Minority Oversampling TEchnique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37FkAUMgeov6"
      },
      "source": [
        "Como hemos visto, una manera de solucionar el problema de que una clase tenga menos muestras que otra, es duplicar las instancias de la clase minoritaria en el conjunto de entrenamiento. Así obtenemos un conjunto balanceado pero esta solución no proporciona información adicional al modelo.\n",
        "\n",
        "En lugar de duplicar las instancias de la clase minoritaria podemos *sintetizar* (crear de manera artificial) nuevas instancias que pertenezcan a esta muestra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtxeHpVlgS5u"
      },
      "source": [
        "Quizás una de las técnicas más usadas es la que se denomina **Synthetic Minority Oversampling TEchnique** (SMOTE). Esta técnica fue descrita por Nitesh Chawla et al. en 2002 en el artículo \"[SMOTE: Synthetic Minority Oversampñling Technique](https://arxiv.org/abs/1106.1813)\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJKmdwyUgm6U"
      },
      "source": [
        "SMOTE funciona seleccionando ejemplos cercanos en el espacio de características, dibujando una línea entre los ejemplos en el espacio de características y dibujando una nueva muestra en un punto a lo largo de esa línea.\n",
        "\n",
        "Específicamente, primero se elige un ejemplo aleatorio de la clase minoritaria. Entonces se encuentran k de los vecinos más cercanos para ese ejemplo (típicamente k = 5). Se elige un vecino seleccionado al azar y se crea un ejemplo sintético en un punto seleccionado al azar entre los dos ejemplos en el espacio de características.\n",
        "Este procedimiento se puede utilizar para crear tantos ejemplos sintéticos para la clase minoritaria como sean necesarios. Como se describe en el documento, sugiere usar primero un submuestreo aleatorio para recortar el número de ejemplos en la clase mayoritaria, luego usar SMOTE para sobremuestrear la clase minoritaria para equilibrar la distribución de clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVUA9jEFhRhc"
      },
      "source": [
        "A continuación vemos un ejemplo de uso , y para ello vamos a necesitar la librería *imbalanced-learn*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QdQVcYhcaO"
      },
      "source": [
        "# Comprobamos que está instalada y cuál es su versión\n",
        "import imblearn\n",
        "print(imblearn.__version__)\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCFsuie1jA5w"
      },
      "source": [
        "Importamos el resto de librerías que se van a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIsBzFphi4f_"
      },
      "source": [
        "# Resto de librerías que vamos a usar\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta8hYzDtjDuS"
      },
      "source": [
        "Definimos un conjunto de datos aleatorio con dos clases. Para ello usamos la instrucción *make_classification* del módulo datasets de la librería Scikit-Learn.\n",
        "\n",
        "Lo que hace este método es crear conjuntos de datos multiclase, asignando a cada clase una o más instancias distribuidas normalmente. Este método está especializado en introducir ruido por medio de las muestras, es decir, genera caracterísitcas correlacionas, redundantes y no informativas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqBkZDwPi8aM"
      },
      "source": [
        "# Creamos el conjunto de datos aleatorio\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "\tn_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# Mostramos como está distribuida la variable objetivo\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdmDfQ41jNPb"
      },
      "source": [
        "Dibujamos como sería nuestro dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul62HF02i-5c"
      },
      "source": [
        "# Dibujamos en un gráfico el dataset creado\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(y == label)[0]\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYYKe7lfjiuQ"
      },
      "source": [
        "Aplicamos la técnica SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JG0UGhwjlAz"
      },
      "source": [
        "# Transformamos el conjunto de datos\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# Obtenemos la nueva distribución de clases en la variable y\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLJO8F99j1sj"
      },
      "source": [
        "# # Dibujamos en un gráfico el dataset transformado\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(y == label)[0]\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqoSbMVNj-Vn"
      },
      "source": [
        "El artículo original sobre SMOTE sugiere combinar SMOTE con un submuestreo aleatorio de la clase mayoritaria. La biblioteca de aprendizaje desequilibrado admite submuestreo aleatorio a través de la clase RandomUnderSampler.\n",
        "\n",
        "Podemos actualizar el ejemplo para sobremuestrear primero la clase minoritaria para tener un 10 por ciento del número de ejemplos de la clase mayoritaria (por ejemplo, alrededor de 1000), luego usar un submuestreo aleatorio para reducir el número de ejemplos en la clase mayoritaria para tener un 50 por ciento más que el clase minoritaria (por ejemplo, alrededor de 2000).\n",
        "\n",
        "Para implementar esto, podemos especificar las proporciones deseadas como argumentos para las clases SMOTE y RandomUnderSampler;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt-hwdt0kLxk"
      },
      "source": [
        "Volvemos a definir el conjunto de datos original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNjhT0_jkPqW"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "\tn_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEZHJp_rkcJb"
      },
      "source": [
        "A continuación, se transforma el conjunto de datos, primero sobremuestreando la clase minoritaria y luego submuestreando la clase mayoritaria.\n",
        "\n",
        "La distribución de clases final después de esta secuencia de transformaciones coincide con una proporción de 1: 2 o aproximadamente 2000 ejemplos en la clase mayoritaria y aproximadamente 1000 ejemplos en la clase minoritaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHcTNSNieeb"
      },
      "source": [
        "# check version number\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "# define pipeline\n",
        "over = SMOTE(sampling_strategy=0.1)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# transform the dataset\n",
        "X, y = pipeline.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: aquí puedes encontrar más información de cómo usar [*pipeline*.](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html)"
      ],
      "metadata": {
        "id": "2h5J00ANPM7_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAg9hf7Hkivr"
      },
      "source": [
        "Mostramos el resultado mediante un *ScatterPlot* o gráfico de puntos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHzZHW5-imVb"
      },
      "source": [
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(y == label)[0]\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeRxqDYMlCOw"
      },
      "source": [
        "###ADASYN: Adaptative Synthetic Sampling Approach For Imbalanced Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3nnknDOlMwJ"
      },
      "source": [
        "Otro enfoque implica la generación de muestras sintéticas inversamente proporcional a la densidad de los ejemplos de la clase minoritaria.\n",
        "\n",
        "Es decir, generar más ejemplos sintéticos en regiones del espacio de características donde la densidad de ejemplos minoritarios es menor que la densidad de la clase mayoritaria.\n",
        "\n",
        "Esta modificación de SMOTE se conoce como Método de muestreo sintético adaptativo, o ADASYN, y lo propuso a Haibo He, et al. en su artículo de 2008 llamado así por el método titulado “[ADASYN: Adaptive Synthetic Sampling Approach For Imbalanced Learning.](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf)”.\n",
        "\n",
        "La idea clave del algoritmo ADASYN es utilizar una distribución de densidad como criterio para decidir automáticamente el número de muestras sintéticas que deben generarse para cada ejemplo de datos minoritarios.\n",
        "\n",
        "Podemos aplicar este procedimiento utilizando la clase ADASYN en la librería *imbalanced-learn*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2x5oIRoleiU"
      },
      "source": [
        "Cargamos las librerías que vamos a necesitar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDT1E_jNlb00"
      },
      "source": [
        "# Oversample and plot imbalanced dataset with ADASYN\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from matplotlib import pyplot\n",
        "from numpy import where"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-8JIbAXlnxb"
      },
      "source": [
        "Volvemos a crear un conjunto de datos de dos clases con dos características para usarlo como ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-fP0cVglkMM"
      },
      "source": [
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
        "\tn_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnH2lrRFl3P3"
      },
      "source": [
        "Usamos el método ADASYN que está en la librería imbalanced-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEF7zHJ-luRl"
      },
      "source": [
        "# transform the dataset\n",
        "oversample = ADASYN()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHCbfHxHmFpr"
      },
      "source": [
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(y == label)[0]\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqVdQaH_lmdW"
      },
      "source": [
        "EJERCICIO: Tanto el método SMOTE y ADASYN se basan, para sintetizar nuevas muestras, en el estudio de los k vecinos de cada una de las instancias. Por defecto se ha comentado que ambos métodos usan k=5. Prueba a ver que ocurre para ambos métodos, con k=3 y con k=7, ¿cambia mucho el conjunto final según el número de vecinos que usemos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBr6xMGVu_Cp"
      },
      "source": [
        "EJERCICIO:\n",
        "\n",
        "Aplica las técnicas de Aumentar la muestra (Oversampling), Disminuir la muestra (Undersampling), SMOTE y ADASYN sobre el conjunto de datos que se encuentra en [https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv ](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
        "\n",
        "Este conjunto de datos es original del *National Institute of Diabetes and Digestive and Kidney Diseases* y se usa para predecir si un paciente tiene diabetes o no, basándose en las medidas de diagnóstico que se recogen en los datos.\n",
        "\n",
        "El nombre de las columnas del conjunto de datos son ['NO_PREG','PLASMA_GLUCOSE','DIASTOLIC_BP','SKIN_THICKNESS','SERUM_INSULIN','BMI','DIA_PEDI_FUNC','AGE','TARGET'] siendo la última, la característica objetivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGlrUGlKo_7n"
      },
      "source": [
        "EJERCICIO EXTRA: Una vez tengas los conjuntos balanceados para los cuatro tipos de métodos, calcula la *accuracy* que sale al aplicar el método de Regresión Logística sobre cada conjunto, teniendo en cuenta que el valor de la *accuracy* ha de estar entre 0 y 1 siendo 1 el mejor resultado: ¿Hay alguno que sea claramente mejor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpcm4-6KpLFm"
      },
      "source": [
        "EJERCICIO EXTRA: En clase de teoría se ha explicado que una estrategia para balancear una clase y de esta manera poder eliminar ruido del dataset (posibles datos anómalos) es usar el método *One-Class Classification* (Clasificación de una clase).\n",
        "\n",
        "Crea una conjunto de datos aleatorio con 10000 muestras, dónde de la clase minoritaria sólo haya 10, siendo la distribución de la muestra 1:1000.\n",
        "\n",
        "La librería *scikit-learn* tiene implementado varios algoritmos de clasificación para una clase, en particular:\n",
        "\n",
        "\n",
        "*   One-class SVM\n",
        "*   Isolation Forest\n",
        "\n",
        "Busca como usar l menos uno de estos dos métodos y ponlo en práctica en el conjunto de datos generado.\n",
        "\n"
      ]
    }
  ]
}